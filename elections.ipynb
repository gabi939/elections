{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans \n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT_PATH = os.path.abspath(os.getcwd())\n",
    "SEED = 170\n",
    "\n",
    "# bycode 2018 excel\n",
    "BYCODE = \"bycode2018\"\n",
    "\n",
    "# index 2018 excel\n",
    "INDEX = \"index 2018\"\n",
    "NATURAL = \"Natural Area\"\n",
    "DISTRICT = \"District\"\n",
    "RELIGION = \"Religion\"\n",
    "SETTLEMENT_TYPE = \"Settlement Type\"\n",
    "\n",
    "\n",
    "# elections data\n",
    "CALPI = \"calpi\"\n",
    "SETTELMENT = \"settelments\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_join(df_1,df_2,column_name):\n",
    "    \"\"\"makes inner-join between dataframes on the specified column\"\"\"\n",
    "    return pd.merge(left=df_1, right=df_2, left_on= column_name, right_on=column_name)\n",
    "\n",
    "def get_index(sheet):\n",
    "    \"returns dataframe of sheet from index 2018 excel\"\n",
    "    path = os.path.join(ROOT_PATH,INDEX+\".xlsx\")\n",
    "    return pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "def get_bycode():\n",
    "    \"\"\"returns dataframe for bycode excel\"\"\"\n",
    "    path = os.path.join(ROOT_PATH,BYCODE+\".xlsx\")\n",
    "    return pd.read_excel(path)\n",
    "\n",
    "def get_data(agg_type, num):\n",
    "    \"\"\"returns dataframe of the requested .xlsx\"\"\" \n",
    "    if type(num) is not str:\n",
    "        num = str(num)\n",
    "        \n",
    "    path = os.path.join(ROOT_PATH,num+agg_type+\".xlsx\")\n",
    "    return pd.read_excel(path,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_parties(df,threshold):\n",
    "    \"\"\"remove parties that didnt pass the threshold\"\"\"\n",
    "    \n",
    "    for column in df.columns[7:]:\n",
    "            if df[column].sum() < threshold:\n",
    "                   df = df.drop(column,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_voters(df):\n",
    "    \"ploting a barchar from dataframe\"\n",
    "    dict={}\n",
    "    for c in df.columns[7:]:\n",
    "        dict[c]=(df[c].sum()/df['valid votes'].sum())*100\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.bar(range(len(dict)), list(dict.values()), align='center')\n",
    "    plt.ylabel('Voter turnout')\n",
    "    plt.xlabel('Parties')\n",
    "    plt.xticks(range(len(dict)), list(dict.keys()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_parties (df):\n",
    "    \"\"\" unites small parties to factions\n",
    "    \n",
    "    We think those factions represent the israeli society\n",
    "    \"\"\"\n",
    "    \n",
    "    d={'United Torah Judaism':'Haredi','Shas':'Haredi', 'Avoda':'Left','Meretz':'Left',\n",
    "       'Consolidation of right-wing parties':'Right','Kolano':'Right','Israel is our Home':'Right','New Right':'Right',\n",
    "        'UAL-Balad':'Arab','Hadash':'Arab' ,'Gesher Avoda':'Left','Joint list':'Arab','right':'Right'\n",
    "        ,'Avoda-Meretz-Gesher':'Left'}\n",
    "    \n",
    "    faction=['Haredi','Right','Arab','Left']\n",
    "    for f in faction:\n",
    "        df.insert(len(df.columns),f ,0)\n",
    "    for c in  df.columns[7:]:\n",
    "        if c in d:\n",
    "            s=df[d[c]]+df[c]\n",
    "            df[d[c]]=s\n",
    "   \n",
    "    for c in d.keys():\n",
    "        if c in df.columns:\n",
    "              df=df.drop(c,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_voting_ratios(df):\n",
    "    \"\"\"normalizing the votes according to proportion of votes per party\"\"\"\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        for c in df.columns[7:]:\n",
    "            x = r[c]/r['valid votes']\n",
    "            df.at[i , c]=x\n",
    "    \n",
    "    colms_to_remove = [\"name\",\"Holders of voting rights\",\"Voters\",\"Disqualified\",\"valid votes\",\"committee code\"]\n",
    "    df = df.drop(labels = colms_to_remove,axis=1) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" \n",
    "    Returns the angle in radians between vectors 'v1' and 'v2'\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def prepare_vectors(df):\n",
    "    \"\"\"calculates the distance and the angle of each vector from the base_vector\"\"\"\n",
    "    \n",
    "    matrix = [] \n",
    "    vector_base = np.zeros(df.shape[1])\n",
    "    vector_base.fill(1)\n",
    "\n",
    "    for row in df:\n",
    "        dist = np.linalg.norm(row)\n",
    "        angle = angle_between(vector_base,row)\n",
    "        matrix.append([dist,angle])\n",
    "        \n",
    "    return np.array(matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_most_voted_colm(df):\n",
    "    \"\"\" adds a column of labels for the most voted faction \"\"\"\n",
    "    temp = df.copy()\n",
    "    temp.drop(labels = [\"code\"],axis=1,inplace = True)\n",
    "    \n",
    "    for c in temp.columns:\n",
    "        temp[c] = pd.to_numeric(temp[c])\n",
    "    \n",
    "    colm = temp.idxmax(axis=1)\n",
    "    df[\"chosen\"] = colm\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_21 = get_data(SETTELMENT,21)\n",
    "df_21 = remove_small_parties(df_21,135720)\n",
    "df_21 = unite_parties(df_21)\n",
    "df_21 = normalize_to_voting_ratios(df_21)\n",
    "df_21 = add_most_voted_colm(df_21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-72a0842b8a9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgofplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mqqplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chosen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mperformance\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mqqplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "s = df['chosen'].value_counts()\n",
    "performance=  np.array(s.values)\n",
    "qqplot(performance)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectors = df_21[df_21.columns.difference(['code','chosen'])]\n",
    "vectors = prepare_vectors(vectors.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"n_clusters\":[3,6],\n",
    "    \"init\":[\"k-means++\", \"random\"],\n",
    "    \"n_init\": [10],\n",
    "    \"max_iter\":[300],\n",
    "    \"precompute_distances\":[False,True],\n",
    "    \"random_state\":[SEED],\n",
    "    \"algorithm\" : [\"auto\", \"full\", \"elkan\"]\n",
    "\n",
    "}\n",
    "gs = GridSearchCV(KMeans(), param,  refit=True, cv=[(slice(None), slice(None))], verbose=1)\n",
    "gs.fit(vectors)\n",
    "y = model.predict(vectors)\n",
    "df_21['Cluster Class'] = pd.Series(y, index=df_21.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(221)\n",
    "plt.scatter(vectors[:, 0], vectors[:, 1], c=y)\n",
    "plt.title(\"Incorrect Number of Blobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "x_var = 'Cluster Class'\n",
    "groupby_var = 'chosen'\n",
    "df_agg = df_21.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [df_21[x_var].values.tolist() for i, df_21 in df_agg]\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, df_21[x_var].unique().__len__(), stacked=False, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(df_21[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.ylim(0, 300)\n",
    "plt.xticks(ticks=bins, labels=np.unique(df_21[x_var]).tolist(), rotation=90, horizontalalignment='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bycode = get_bycode()\n",
    "index = get_index(DISTRICT)\n",
    "df = inner_join(df_21,bycode,\"code\")\n",
    "df = inner_join(df,index,\"District code\")\n",
    "df_211 = df[[\"Cluster Class\",\"District code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_21' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fdae4217ceec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Cluster Class'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgroupby_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Religion code'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_agg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_21\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroupby_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroupby_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdf_21\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_21\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_agg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Draw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_21' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "x_var = 'Cluster Class'\n",
    "groupby_var = 'Religion code'\n",
    "df_agg = df_21.loc[:, [x_var, groupby_var]].groupby(groupby_var)\n",
    "vals = [df_21[x_var].values.tolist() for i, df_21 in df_agg]\n",
    "# Draw\n",
    "plt.figure(figsize=(16,9), dpi= 80)\n",
    "colors = [plt.cm.Spectral(i/float(len(vals)-1)) for i in range(len(vals))]\n",
    "n, bins, patches = plt.hist(vals, df_21[x_var].unique().__len__(), stacked=False, density=False, color=colors[:len(vals)])\n",
    "\n",
    "# Decoration\n",
    "plt.legend({group:col for group, col in zip(np.unique(df_21[groupby_var]).tolist(), colors[:len(vals)])})\n",
    "plt.title(f\"Stacked Histogram of ${x_var}$ colored by ${groupby_var}$\", fontsize=22)\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.ylim(0, 150)\n",
    "plt.xticks(ticks=bins, labels=np.unique(df_21[x_var]).tolist(), rotation=90, horizontalalignment='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GaussianMixture\n",
    "clf = mixture.GaussianMixture(n_components=2, covariance_type='full')\n",
    "clf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataRegress(num , RF ,n=None):\n",
    "    \n",
    "        df = get_data(SETTELMENT,num)\n",
    "        df = remove_small_parties(df,135720)\n",
    "        df = unite_parties(df)\n",
    "        if RF:\n",
    "            return df[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\"Likud\",\n",
    "                   \"Blue and white\",\"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\"]]\n",
    "        if n == 1:\n",
    "            return df[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\"Likud\",\n",
    "                   \"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\",\"Blue and white\"]]\n",
    "        elif n == 2:\n",
    "            return df[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\n",
    "                   \"Blue and white\",\"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\",\"Likud\"]]\n",
    "        else:\n",
    "            return df[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\"Likud\",\n",
    "                   \"Blue and white\",\"Haredi\",\"Right\",\"Left\",\"valid votes\",\"Arab\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.9s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.0s finished\n",
      "C:\\Users\\mzmir\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predection for ['AYYELET HASHAHAR'] is 591.6584960317459 while the true value is 585\n",
      "predection for ['ELAT'] is 24865.21497023809 while the true value is 22636\n",
      "predection for ['HAIFA'] is 143864.38975992048 while the true value is 144625\n",
      "predection for ['SAKHNIN'] is 15874.265541666677 while the true value is 17085\n",
      "predection for ['QAZRIN'] is 3641.7413353174593 while the true value is 3498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import  metrics\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200, 250],  # The number of trees in the forest.\n",
    "    'max_depth': [None, 50, 60, 70],  # The maximum depth of the tree.\n",
    "    'max_features': ['sqrt', None],  # he number of features to consider when looking for the best split\n",
    "    'min_samples_split': [2, 5, 10],  # The minimum number of samples required to split an internal node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees.\n",
    "}\n",
    "\n",
    "df21 =getdataRegress(21, True)\n",
    "df22 =getdataRegress(22, True)\n",
    "df23 = get_data(SETTELMENT,23)\n",
    "df23 = remove_small_parties(df23,135720)\n",
    "df23 = unite_parties(df23)\n",
    "a=[\"HAIFA\",\"ELAT\",\"AYYELET HASHAHAR\",\"SAKHNIN\",\"QAZRIN\"]\n",
    "df23 = df23[df23.name.isin(a)]\n",
    "locations=df23[['name']].values.tolist()\n",
    "df23=df23[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\"Likud\",\n",
    "           \"Blue and white\",\"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\"]]\n",
    "\n",
    "df=pd.concat([df21, df22])\n",
    "x_train=df.iloc[:,:-1]\n",
    "y_train=df.iloc[:,-1]\n",
    "x_test=df23.iloc[:,:-1]\n",
    "y_test=df23.iloc[:,-1]\n",
    "\n",
    "estimator = RandomForestRegressor(random_state=SEED)\n",
    "\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs=-1,\n",
    "                        scoring='neg_mean_squared_error', cv=5,\n",
    "                        n_iter=1, verbose=1, random_state=SEED)\n",
    "\n",
    "rs.fit(x_train,y_train)\n",
    "predict_y = rs.predict(x_test)\n",
    "actual=df23.iloc[:,-1].values\n",
    "i=0\n",
    "while i< len(predict_y):\n",
    "        print(\"predection for \"+str(locations[i])+ \" is \"+str(predict_y[i])+\" while the true value is \"+\n",
    "                                    str(actual[i]))\n",
    "        i=i+1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     committee code  Voters Disqualified Holders of voting rights  Likud  \\\n",
      "0                17     377            0                      517    128   \n",
      "1                 2     245            0                      332     93   \n",
      "2                17     287            0                      406     57   \n",
      "3                18     373            0                      502     25   \n",
      "4                17     228            1                      308    158   \n",
      "...             ...     ...          ...                      ...    ...   \n",
      "1209              8   21729          133                    34213   7385   \n",
      "1210              8   20697          203                    36529   8626   \n",
      "1211             19   34603           98                    45835   6954   \n",
      "1212              9    7536           21                    10142   1404   \n",
      "1213             99  282442         2226                        0  77953   \n",
      "\n",
      "     Haredi  Right   Arab   Left valid votes Blue and white  \n",
      "0        47     39      0     44         377             98  \n",
      "1       108     11      0      2         245              6  \n",
      "2         5     23      1     37         287             94  \n",
      "3         3     35      0     56         373            216  \n",
      "4        40      9      0      1         227             13  \n",
      "...     ...    ...    ...    ...         ...            ...  \n",
      "1209    951   3162     19   1659       21596           8097  \n",
      "1210   1066   4965     13    888       20494           4535  \n",
      "1211    984   2561     59   5293       34505          18294  \n",
      "1212    135    589     25   1526        7515           3746  \n",
      "1213  29247  38829  11974  27072      280216          84654  \n",
      "\n",
      "[1214 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mzmir\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predection for ['BENE BERAQ'] is 5020.254826254826 while the true value is 1133\n",
      "predection for ['DALIYAT AL-KARMEL'] is 1454.009900990099 while the true value is 5200\n",
      "predection for ['JERUSALEM'] is 32452.169851380044 while the true value is 32800\n",
      "predection for [\"KARMI'EL\"] is 4377.3185840707965 while the true value is 6627\n",
      "predection for ['SAKHNIN'] is 1454.009900990099 while the true value is 120\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "df21=getdataRegress(21,False,1)\n",
    "df22=getdataRegress(22,False,1)\n",
    "df23 = get_data(SETTELMENT,23)\n",
    "df23 = remove_small_parties(df23,135720)\n",
    "df23 = unite_parties(df23)\n",
    "a=[\"JERUSALEM\",\"BENE BERAQ\",\"SAKHNIN\",\"KARMI'EL\",\"DALIYAT AL-KARMEL\"]\n",
    "df23 = df23[df23.name.isin(a)]\n",
    "locations=df23[['name']].values\n",
    "df23=df23[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\"Likud\",\n",
    "           \"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\",\"Blue and white\"]]\n",
    "print(df22)\n",
    "df=pd.concat([df21, df22])\n",
    "x_train=df.iloc[:,:-1]\n",
    "y_train=df.iloc[:,-1]\n",
    "x_test=df23.iloc[:,:-1]\n",
    "y_test=df23.iloc[:,-1]\n",
    "param_grid = {'n_estimators':[50,100,150,200,250], #Number of weak learners to train iteratively., \n",
    "                  'learning_rate':[0.001, 0.01, 0.1, 1], #It contributes to the weights of weak learners. It uses 1 as a default value.,\n",
    "                   'loss' : ['linear', 'square', 'exponential']}\n",
    "\n",
    "rs = RandomizedSearchCV(AdaBoostRegressor(),param_grid,cv=5,n_iter = 10,n_jobs=-1)\n",
    "rs.fit(x_train, y_train)\n",
    "ADB_best=rs.best_estimator_\n",
    "adb = AdaBoostRegressor(ADB_best)\n",
    "adb.fit(x_train, y_train)\n",
    "predict_y = adb.predict(x_test)\n",
    "actual=df23.iloc[:,-1].values\n",
    "i=0\n",
    "while i< len(predict_y):\n",
    "        print(\"predection for \"+str(locations[i])+ \" is \"+str(predict_y[i])+\" while the true value is \"+\n",
    "                                    str(actual[i]))\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     committee code  Voters Disqualified Holders of voting rights  \\\n",
      "0                17     377            0                      517   \n",
      "1                 2     245            0                      332   \n",
      "2                17     287            0                      406   \n",
      "3                18     373            0                      502   \n",
      "4                17     228            1                      308   \n",
      "...             ...     ...          ...                      ...   \n",
      "1209              8   21729          133                    34213   \n",
      "1210              8   20697          203                    36529   \n",
      "1211             19   34603           98                    45835   \n",
      "1212              9    7536           21                    10142   \n",
      "1213             99  282442         2226                        0   \n",
      "\n",
      "     Blue and white Haredi  Right   Arab   Left valid votes  Likud  \n",
      "0                98     47     39      0     44         377    128  \n",
      "1                 6    108     11      0      2         245     93  \n",
      "2                94      5     23      1     37         287     57  \n",
      "3               216      3     35      0     56         373     25  \n",
      "4                13     40      9      0      1         227    158  \n",
      "...             ...    ...    ...    ...    ...         ...    ...  \n",
      "1209           8097    951   3162     19   1659       21596   7385  \n",
      "1210           4535   1066   4965     13    888       20494   8626  \n",
      "1211          18294    984   2561     59   5293       34505   6954  \n",
      "1212           3746    135    589     25   1526        7515   1404  \n",
      "1213          84654  29247  38829  11974  27072      280216  77953  \n",
      "\n",
      "[1214 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mzmir\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predection for ['BENE BERAQ'] is 5361.301282051282 while the true value is 4951\n",
      "predection for ['DALIYAT AL-KARMEL'] is 441.69391304347823 while the true value is 407\n",
      "predection for ['JERUSALEM'] is 54597.94594594595 while the true value is 72601\n",
      "predection for [\"KARMI'EL\"] is 9922.970588235294 while the true value is 8879\n",
      "predection for ['SAKHNIN'] is 534.407949790795 while the true value is 39\n"
     ]
    }
   ],
   "source": [
    "df21=getdataRegress(21,False,2)\n",
    "df22=getdataRegress(22,False,2)\n",
    "df23 = get_data(SETTELMENT,23)\n",
    "df23 = remove_small_parties(df23,135720)\n",
    "df23 = unite_parties(df23)\n",
    "df23 = df23[df23.name.isin(a)]\n",
    "locations=df23[['name']].values\n",
    "df23=df23[[\"committee code\",\"Voters\",\"Disqualified\",\"Holders of voting rights\",\n",
    "                   \"Blue and white\",\"Haredi\",\"Right\",\"Arab\",\"Left\",\"valid votes\",\"Likud\"]]\n",
    "print(df22)\n",
    "df=pd.concat([df21, df22])\n",
    "x_train=df.iloc[:,:-1]\n",
    "y_train=df.iloc[:,-1]\n",
    "x_test=df23.iloc[:,:-1]\n",
    "y_test=df23.iloc[:,-1]\n",
    "param_grid = {'n_estimators':[50,100,150,200,250], #Number of weak learners to train iteratively., \n",
    "                  'learning_rate':[0.001, 0.01, 0.1, 1], #It contributes to the weights of weak learners. It uses 1 as a default value.,\n",
    "                   'loss' : ['linear', 'square', 'exponential']}\n",
    "\n",
    "rs = RandomizedSearchCV(AdaBoostRegressor(),param_grid,cv=5,n_iter = 10,n_jobs=-1)\n",
    "rs.fit(x_train, y_train)\n",
    "ADB_best=rs.best_estimator_\n",
    "adb = AdaBoostRegressor(ADB_best)\n",
    "adb.fit(x_train, y_train)\n",
    "predict_y = adb.predict(x_test)\n",
    "actual=df23.iloc[:,-1].values\n",
    "i=0\n",
    "while i< len(predict_y):\n",
    "        print(\"predection for \"+str(locations[i])+ \" is \"+str(predict_y[i])+\" while the true value is \"+\n",
    "                                    str(actual[i]))\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
